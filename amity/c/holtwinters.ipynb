{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AQI Prediction Result:\n",
      "{'City': 'Agra', 'Future Date': '2024-06-10', 'Predicted AQI': -572.74, 'Prediction Confidence': 105.4}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"AQI_of_different_Regions_Final.csv\"  # Update with your actual file path\n",
    "df=pd.read_csv(r'C:\\Users\\ASUS\\Desktop\\Climate1\\AQI.csv')\n",
    "\n",
    "def train_and_forecast(city, future_date):\n",
    "    \"\"\"\n",
    "    Trains the Holt-Winters model on AQI data for a given city and predicts AQI for a future date.\n",
    "\n",
    "    Parameters:\n",
    "    - city (str): Name of the city.\n",
    "    - future_date (str): Future date in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    - Predicted AQI value and confidence probability.\n",
    "    \"\"\"\n",
    "    # Filter data for the selected city\n",
    "    df_city = df[df['City'] == city].copy()\n",
    "    \n",
    "    if df_city.empty:\n",
    "        return f\"City '{city}' not found in the dataset.\"\n",
    "    \n",
    "    # Convert date column to datetime and set as index\n",
    "    df_city['date'] = pd.to_datetime(df_city['date'])\n",
    "    df_city.set_index('date', inplace=True)\n",
    "    \n",
    "    # Ensure daily frequency\n",
    "    df_city = df_city.asfreq('D')\n",
    "    \n",
    "    # Fill missing AQI values using interpolation\n",
    "    df_city['Index Value'] = df_city['Index Value'].interpolate()\n",
    "\n",
    "    # Define seasonal period (assumed yearly seasonality)\n",
    "    seasonal_period = 365 if len(df_city) > 365 else 30  # Use 30 if dataset is small\n",
    "    \n",
    "    # Train Holt-Winters model\n",
    "    model = ExponentialSmoothing(\n",
    "        df_city['Index Value'],\n",
    "        trend='add',\n",
    "        seasonal='add',\n",
    "        seasonal_periods=seasonal_period\n",
    "    ).fit()\n",
    "    \n",
    "    # Convert future_date to datetime\n",
    "    future_date = pd.to_datetime(future_date)\n",
    "    \n",
    "    # Predict AQI for the given future date\n",
    "    days_ahead = (future_date - df_city.index[-1]).days\n",
    "    if days_ahead < 1:\n",
    "        return \"Future date must be beyond the last recorded date.\"\n",
    "    \n",
    "    predicted_aqi = model.forecast(steps=days_ahead).iloc[-1]\n",
    "\n",
    "    # Estimate prediction confidence using past error\n",
    "    past_predictions = model.fittedvalues\n",
    "    actual_values = df_city['Index Value'].iloc[:len(past_predictions)]\n",
    "    error = np.abs(past_predictions - actual_values)\n",
    "    \n",
    "    # Calculate mean absolute error (MAE) as confidence indicator\n",
    "    mae = np.mean(error)\n",
    "    confidence_prob = max(0, 1 - (mae / predicted_aqi))  # Normalize confidence\n",
    "\n",
    "    return {\n",
    "        \"City\": city,\n",
    "        \"Future Date\": future_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"Predicted AQI\": round(predicted_aqi, 2),\n",
    "        \"Prediction Confidence\": round(confidence_prob * 100, 2)  # Percentage\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    city_name = input(\"Enter city name: \")\n",
    "    future_date = input(\"Enter future date (YYYY-MM-DD): \")\n",
    "    \n",
    "    result = train_and_forecast(city_name, future_date)\n",
    "    print(\"\\nAQI Prediction Result:\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AQI Prediction Result:\n",
      "{'City': 'Agra', 'Future Date': '2025-02-25', 'Predicted AQI': 377.54, 'Prediction Confidence': 73.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anacondaa\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"AQI_of_different_Regions_Final.csv\"  # Update with your actual file path\n",
    "\n",
    "\n",
    "def train_and_forecast(city, future_date):\n",
    "    \"\"\"\n",
    "    Trains the Holt-Winters model on AQI data for a given city and predicts AQI for a future date.\n",
    "\n",
    "    Parameters:\n",
    "    - city (str): Name of the city.\n",
    "    - future_date (str): Future date in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    - Predicted AQI value and confidence probability.\n",
    "    \"\"\"\n",
    "    # Filter data for the selected city\n",
    "    df_city = df[df['City'] == city].copy()\n",
    "    \n",
    "    if df_city.empty:\n",
    "        return f\"City '{city}' not found in the dataset.\"\n",
    "    \n",
    "    # Convert date column to datetime and set as index\n",
    "    df_city['date'] = pd.to_datetime(df_city['date'])\n",
    "    df_city.set_index('date', inplace=True)\n",
    "    \n",
    "    # Ensure daily frequency\n",
    "    df_city = df_city.asfreq('D')\n",
    "    \n",
    "    # Fill missing AQI values using interpolation\n",
    "    df_city['Index Value'] = df_city['Index Value'].interpolate()\n",
    "\n",
    "    # Define seasonal period (assumed yearly seasonality)\n",
    "    seasonal_period = 365 if len(df_city) > 365 else 30  # Use 30 if dataset is small\n",
    "    \n",
    "    # Train Holt-Winters model (use multiplicative trend to prevent negative AQI)\n",
    "    model = ExponentialSmoothing(\n",
    "        df_city['Index Value'],\n",
    "        trend='mul',  # Changed from 'add' to 'mul'\n",
    "        seasonal='mul',  # Changed from 'add' to 'mul'\n",
    "        seasonal_periods=seasonal_period\n",
    "    ).fit()\n",
    "    \n",
    "    # Convert future_date to datetime\n",
    "    future_date = pd.to_datetime(future_date)\n",
    "    \n",
    "    # Predict AQI for the given future date\n",
    "    days_ahead = (future_date - df_city.index[-1]).days\n",
    "    if days_ahead < 1:\n",
    "        return \"Future date must be beyond the last recorded date.\"\n",
    "    \n",
    "    predicted_aqi = model.forecast(steps=days_ahead).iloc[-1]\n",
    "\n",
    "    # Clip negative AQI values to zero\n",
    "    predicted_aqi = max(predicted_aqi, 0)\n",
    "\n",
    "    # Estimate prediction confidence using past error\n",
    "    past_predictions = model.fittedvalues\n",
    "    actual_values = df_city['Index Value'].iloc[:len(past_predictions)]\n",
    "    error = np.abs(past_predictions - actual_values)\n",
    "\n",
    "    # Compute MAPE (Mean Absolute Percentage Error) for confidence estimation\n",
    "    mape = np.mean((error / actual_values.replace(0, np.nan)).dropna())  # Avoid divide by zero\n",
    "\n",
    "    # Convert MAPE to confidence score (higher MAPE means lower confidence)\n",
    "    confidence_prob = max(0, 1 - mape) * 100  # Normalize confidence to percentage\n",
    "\n",
    "    return {\n",
    "        \"City\": city,\n",
    "        \"Future Date\": future_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"Predicted AQI\": round(predicted_aqi, 2),\n",
    "        \"Prediction Confidence\": round(confidence_prob, 2)  # Percentage\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    city_name = input(\"Enter city name: \")\n",
    "    future_date = input(\"Enter future date (YYYY-MM-DD): \")\n",
    "    \n",
    "    result = train_and_forecast(city_name, future_date)\n",
    "    print(\"\\nAQI Prediction Result:\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "endog must be strictly positive when usingmultiplicative trend or seasonal components.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m city_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter city name: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m future_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter future date (YYYY-MM-DD): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 114\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_hybrid_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHybrid AQI Prediction Result:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[10], line 39\u001b[0m, in \u001b[0;36mtrain_hybrid_model\u001b[1;34m(city, future_date)\u001b[0m\n\u001b[0;32m     36\u001b[0m df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex Value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex Value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex Value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(\u001b[38;5;241m7\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Train Holt-Winters Model (choosing best parameters)\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m model_hw \u001b[38;5;241m=\u001b[39m \u001b[43mExponentialSmoothing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_city\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIndex Value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmul\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseasonal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmul\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseasonal_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m365\u001b[39;49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Holt-Winters Forecast\u001b[39;00m\n\u001b[0;32m     47\u001b[0m df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHW_Predicted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model_hw\u001b[38;5;241m.\u001b[39mfittedvalues\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\pandas\\util\\_decorators.py:213\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    212\u001b[0m     kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:248\u001b[0m, in \u001b[0;36mExponentialSmoothing.__init__\u001b[1;34m(self, endog, trend, damped_trend, seasonal, seasonal_periods, initialization_method, initial_level, initial_trend, initial_seasonal, use_boxcox, bounds, dates, freq, missing)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_seasonal \u001b[38;5;241m=\u001b[39m seasonal \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseasonal \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendog must be strictly positive when using\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiplicative trend or seasonal components.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m     )\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdamped_trend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_trend:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only dampen the trend component\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: endog must be strictly positive when usingmultiplicative trend or seasonal components."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "\n",
    "def train_hybrid_model(city, future_date):\n",
    "    \"\"\"\n",
    "    Trains a hybrid AQI prediction model using Holt-Winters and XGBoost.\n",
    "    \n",
    "    Parameters:\n",
    "    - city (str): City name\n",
    "    - future_date (str): Future date in 'YYYY-MM-DD' format\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted AQI value and confidence range\n",
    "    \"\"\"\n",
    "    # Filter data for the selected city\n",
    "    df_city = df[df['City'] == city].copy()\n",
    "    \n",
    "    if df_city.empty:\n",
    "        return f\"City '{city}' not found in the dataset.\"\n",
    "\n",
    "    # Convert date column to datetime and set as index\n",
    "    df_city['date'] = pd.to_datetime(df_city['date'])\n",
    "    df_city.set_index('date', inplace=True)\n",
    "    \n",
    "    # Ensure daily frequency\n",
    "    df_city = df_city.asfreq('D')\n",
    "    \n",
    "    # Fill missing AQI values using rolling mean\n",
    "    df_city['Index Value'] = df_city['Index Value'].fillna(df_city['Index Value'].rolling(7, min_periods=1).mean())\n",
    "\n",
    "    # Train Holt-Winters Model (choosing best parameters)\n",
    "    model_hw = ExponentialSmoothing(\n",
    "        df_city['Index Value'], \n",
    "        trend='mul', \n",
    "        seasonal='mul', \n",
    "        seasonal_periods=365\n",
    "    ).fit()\n",
    "\n",
    "    # Holt-Winters Forecast\n",
    "    df_city['HW_Predicted'] = model_hw.fittedvalues\n",
    "\n",
    "    # Calculate residuals (errors)\n",
    "    df_city['Error'] = df_city['Index Value'] - df_city['HW_Predicted']\n",
    "\n",
    "    # Feature Engineering for XGBoost\n",
    "    df_city['day'] = df_city.index.day\n",
    "    df_city['month'] = df_city.index.month\n",
    "    df_city['year'] = df_city.index.year\n",
    "    df_city['dayofweek'] = df_city.index.dayofweek\n",
    "\n",
    "    # Prepare training data for XGBoost\n",
    "    features = ['day', 'month', 'year', 'dayofweek']\n",
    "    X = df_city[features]\n",
    "    y = df_city['Error']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Train XGBoost on errors\n",
    "    model_xgb = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Predict future AQI\n",
    "    future_date = pd.to_datetime(future_date)\n",
    "    days_ahead = (future_date - df_city.index[-1]).days\n",
    "    if days_ahead < 1:\n",
    "        return \"Future date must be beyond the last recorded date.\"\n",
    "\n",
    "    # Holt-Winters Prediction\n",
    "    hw_forecast = model_hw.forecast(steps=days_ahead).iloc[-1]\n",
    "\n",
    "    # Create future features for XGBoost\n",
    "    future_features = pd.DataFrame({\n",
    "        \"day\": [future_date.day],\n",
    "        \"month\": [future_date.month],\n",
    "        \"year\": [future_date.year],\n",
    "        \"dayofweek\": [future_date.dayofweek]\n",
    "    })\n",
    "\n",
    "    # XGBoost Prediction (error correction)\n",
    "    xgb_correction = model_xgb.predict(future_features)[0]\n",
    "\n",
    "    # Final AQI prediction (Holt-Winters + XGBoost correction)\n",
    "    final_prediction = hw_forecast + xgb_correction\n",
    "    final_prediction = max(final_prediction, 0)  # Ensure AQI is non-negative\n",
    "\n",
    "    # Compute confidence using MAE of past predictions\n",
    "    past_hw_predictions = model_hw.fittedvalues\n",
    "    past_actual = df_city['Index Value'].iloc[:len(past_hw_predictions)]\n",
    "    past_errors = np.abs(past_hw_predictions - past_actual)\n",
    "    mape = np.mean((past_errors / past_actual.replace(0, np.nan)).dropna())  # Avoid division by zero\n",
    "\n",
    "    confidence_prob = max(0, 1 - mape) * 100  # Convert MAPE to confidence percentage\n",
    "\n",
    "    return {\n",
    "        \"City\": city,\n",
    "        \"Future Date\": future_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"Predicted AQI\": round(final_prediction, 2),\n",
    "        \"Prediction Confidence\": round(confidence_prob, 2)  # Percentage\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    city_name = input(\"Enter city name: \")\n",
    "    future_date = input(\"Enter future date (YYYY-MM-DD): \")\n",
    "    \n",
    "    result = train_hybrid_model(city_name, future_date)\n",
    "    print(\"\\nHybrid AQI Prediction Result:\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex Value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex Value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan)\u001b[38;5;241m.\u001b[39mfillna(df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex Value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Fit Additive Model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model_add \u001b[38;5;241m=\u001b[39m \u001b[43mExponentialSmoothing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_city\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIndex Value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m365\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     26\u001b[0m df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHW_Add\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model_add\u001b[38;5;241m.\u001b[39mfittedvalues\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Fit Multiplicative Model (only if all values are positive)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\pandas\\util\\_decorators.py:213\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    212\u001b[0m     kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:297\u001b[0m, in \u001b[0;36mExponentialSmoothing.__init__\u001b[1;34m(self, endog, trend, damped_trend, seasonal, seasonal_periods, initialization_method, initial_level, initial_trend, initial_seasonal, use_boxcox, bounds, dates, freq, missing)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lambda \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boxcox()\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fixed_parameters \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:435\u001b[0m, in \u001b[0;36mExponentialSmoothing._initialize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialization_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimated\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnobs \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseasonal_periods \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_heuristic()\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:442\u001b[0m, in \u001b[0;36mExponentialSmoothing._initialize_simple\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrend \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_trend \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    441\u001b[0m seasonal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseasonal \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_seasonal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m lvl, trend, seas \u001b[38;5;241m=\u001b[39m \u001b[43m_initialization_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseasonal_periods\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_level \u001b[38;5;241m=\u001b[39m lvl\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_trend \u001b[38;5;241m=\u001b[39m trend\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\statsmodels\\tsa\\exponential_smoothing\\initialization.py:26\u001b[0m, in \u001b[0;36m_initialization_simple\u001b[1;34m(endog, trend, seasonal, seasonal_periods)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Seasonal\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nobs \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m seasonal_periods:\n\u001b[1;32m---> 26\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot compute initial seasonals using\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m heuristic method with less than two full\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     28\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m seasonal cycles in the data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m     initial_level \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(endog[:seasonal_periods])\n\u001b[0;32m     31\u001b[0m     m \u001b[38;5;241m=\u001b[39m seasonal_periods\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "df=pd.read_csv(r'C:\\Users\\ASUS\\Desktop\\Climate1\\AQI.csv')\n",
    "# Choose a city (modify as needed)\n",
    "city = \"Delhi\"\n",
    "df_city = df[df['City'] == city].copy()\n",
    "\n",
    "# Convert date column to datetime and set as index\n",
    "df_city['date'] = pd.to_datetime(df_city['date'])\n",
    "df_city.set_index('date', inplace=True)\n",
    "df_city = df_city.asfreq('D')\n",
    "\n",
    "# Fill missing values with rolling mean\n",
    "df_city['Index Value'] = df_city['Index Value'].fillna(df_city['Index Value'].rolling(7, min_periods=1).mean())\n",
    "\n",
    "# Ensure all values are positive for multiplicative test\n",
    "df_city['Index Value'] = df_city['Index Value'].replace(0, np.nan).fillna(df_city['Index Value'].median()) + 1\n",
    "\n",
    "# Fit Additive Model\n",
    "model_add = ExponentialSmoothing(df_city['Index Value'], trend='add', seasonal='add', seasonal_periods=365).fit()\n",
    "df_city['HW_Add'] = model_add.fittedvalues\n",
    "\n",
    "# Fit Multiplicative Model (only if all values are positive)\n",
    "try:\n",
    "    model_mul = ExponentialSmoothing(df_city['Index Value'], trend='mul', seasonal='mul', seasonal_periods=365).fit()\n",
    "    df_city['HW_Mul'] = model_mul.fittedvalues\n",
    "    multiplicative_valid = True\n",
    "except ValueError as e:\n",
    "    print(\"Multiplicative model failed:\", e)\n",
    "    multiplicative_valid = False\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_city.index, df_city['Index Value'], label=\"Actual AQI\", color='black', alpha=0.7)\n",
    "plt.plot(df_city.index, df_city['HW_Add'], label=\"Holt-Winters Additive\", linestyle=\"dashed\")\n",
    "if multiplicative_valid:\n",
    "    plt.plot(df_city.index, df_city['HW_Mul'], label=\"Holt-Winters Multiplicative\", linestyle=\"dotted\")\n",
    "plt.legend()\n",
    "plt.title(f\"Holt-Winters Model Comparison for {city}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"AQI\")\n",
    "plt.show()\n",
    "\n",
    "# Compute Mean Absolute Error (MAE) to compare models\n",
    "mae_add = np.mean(np.abs(df_city['Index Value'] - df_city['HW_Add']))\n",
    "mae_mul = np.mean(np.abs(df_city['Index Value'] - df_city['HW_Mul'])) if multiplicative_valid else float(\"inf\")\n",
    "\n",
    "print(f\"MAE (Additive): {mae_add:.2f}\")\n",
    "if multiplicative_valid:\n",
    "    print(f\"MAE (Multiplicative): {mae_mul:.2f}\")\n",
    "\n",
    "# Recommend best model\n",
    "if mae_mul < mae_add and multiplicative_valid:\n",
    "    print(\"✅ Multiplicative Model is better.\")\n",
    "else:\n",
    "    print(\"✅ Additive Model is better.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anacondaa\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[15:52:44] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:514: Check failed: valid: Label contains NaN, infinity or a value too large.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Train XGBoost model\u001b[39;00m\n\u001b[0;32m     51\u001b[0m model_xgb \u001b[38;5;241m=\u001b[39m XGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m \u001b[43mmodel_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m xgb_pred \u001b[38;5;241m=\u001b[39m model_xgb\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Final prediction\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\sklearn.py:1143\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m   1142\u001b[0m     evals_result: TrainingCallback\u001b[38;5;241m.\u001b[39mEvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1143\u001b[0m     train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1161\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\sklearn.py:603\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    584\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    585\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    599\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    601\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\sklearn.py:1065\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1065\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_bin\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:1573\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1554\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m         )\n\u001b[0;32m   1567\u001b[0m     ):\n\u001b[0;32m   1568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1571\u001b[0m         )\n\u001b[1;32m-> 1573\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:1632\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1620\u001b[0m config \u001b[38;5;241m=\u001b[39m make_jcargs(\n\u001b[0;32m   1621\u001b[0m     nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnthread, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m   1622\u001b[0m )\n\u001b[0;32m   1623\u001b[0m ret \u001b[38;5;241m=\u001b[39m _LIB\u001b[38;5;241m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[0;32m   1624\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1625\u001b[0m     it\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(handle),\n\u001b[0;32m   1631\u001b[0m )\n\u001b[1;32m-> 1632\u001b[0m \u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[0;32m   1634\u001b[0m _check_call(ret)\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:569\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    567\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:550\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[1;34m(self, fn, dft_ret)\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[0;32m    555\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:637\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\data.py:1402\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1402\u001b[0m \u001b[43minput_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:626\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[1;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n\u001b[0;32m    625\u001b[0m dispatch_proxy_set_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy, new, cat_codes)\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_ref \u001b[38;5;241m=\u001b[39m ref\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:954\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[1;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_weight(weight)\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:1092\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m \n\u001b[0;32m   1085\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;124;03m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m-> 1092\u001b[0m \u001b[43mdispatch_meta_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\data.py:1348\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[1;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_series(data):\n\u001b[1;32m-> 1348\u001b[0m     \u001b[43m_meta_from_pandas_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_dlpack(data):\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\data.py:679\u001b[0m, in \u001b[0;36m_meta_from_pandas_series\u001b[1;34m(data, name, dtype, handle)\u001b[0m\n\u001b[0;32m    677\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_dense()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 679\u001b[0m \u001b[43m_meta_from_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\data.py:1279\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[1;34m(data, field, dtype, handle)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasked array is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1278\u001b[0m interface_str \u001b[38;5;241m=\u001b[39m _array_interface(data)\n\u001b[1;32m-> 1279\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGDMatrixSetInfoFromInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\xgboost\\core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [15:52:44] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:514: Check failed: valid: Label contains NaN, infinity or a value too large."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load dataset\n",
    "df=pd.read_csv(r'C:\\Users\\ASUS\\Desktop\\Climate1\\AQI.csv')  # Update with your file path\n",
    "\n",
    "# Convert date column to datetime format\n",
    "\n",
    "df_city['Index Value'] = df_city['Index Value'].interpolate(method='linear')\n",
    "\n",
    "# Count unique days per city\n",
    "city_data_counts = df.groupby('City')['date'].nunique()\n",
    "\n",
    "# Categorize cities\n",
    "cities_with_2_years_data = city_data_counts[city_data_counts > 730].index.tolist()\n",
    "cities_with_less_than_2_years_data = city_data_counts[city_data_counts <= 730].index.tolist()\n",
    "\n",
    "# Store prediction results\n",
    "prediction_results = []\n",
    "\n",
    "for city in df['City'].unique():\n",
    "    df_city = df[df['City'] == city].copy()\n",
    "    df_city.set_index('date', inplace=True)\n",
    "    df_city = df_city.asfreq('D')\n",
    "    \n",
    "    # Fill missing values using rolling mean\n",
    "    df_city['Index Value'] = df_city['Index Value'].fillna(df_city['Index Value'].rolling(7, min_periods=1).mean())\n",
    "    \n",
    "    # Define features and target\n",
    "    df_city['day_of_year'] = df_city.index.dayofyear\n",
    "    df_city['year'] = df_city.index.year\n",
    "    X = df_city[['day_of_year', 'year']]\n",
    "    y = df_city['Index Value']\n",
    "    \n",
    "    # Split data for training/testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    if city in cities_with_2_years_data:\n",
    "        # Apply Holt-Winters\n",
    "        seasonal_periods = min(365, len(df_city) // 2)\n",
    "        model_hw = ExponentialSmoothing(y_train, trend='add', seasonal='add', seasonal_periods=seasonal_periods).fit()\n",
    "        hw_pred = model_hw.forecast(len(X_test))\n",
    "        X_train['hw_prediction'] = model_hw.fittedvalues\n",
    "        X_test['hw_prediction'] = hw_pred\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    model_xgb = XGBRegressor(objective='reg:squarederror', n_estimators=50, learning_rate=0.1, max_depth=3)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    xgb_pred = model_xgb.predict(X_test)\n",
    "    \n",
    "    # Final prediction\n",
    "    final_prediction = xgb_pred if city in cities_with_less_than_2_years_data else (0.5 * xgb_pred + 0.5 * hw_pred)\n",
    "    \n",
    "    # Compute confidence\n",
    "    mae = mean_absolute_error(y_test, final_prediction)\n",
    "    confidence = max(0, 100 - (mae / np.mean(y_test)) * 100)\n",
    "    \n",
    "    # Store results\n",
    "    prediction_results.append({\n",
    "        \"City\": city,\n",
    "        \"Predicted AQI\": round(final_prediction[-1], 2),\n",
    "        \"Prediction Confidence\": round(confidence, 2)\n",
    "    })\n",
    "\n",
    "# Output predictions\n",
    "for result in prediction_results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_26200\\2509473081.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"Predicted AQI\": round(final_prediction[-1], 2),\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m df_city \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m city]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     35\u001b[0m df_city\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 36\u001b[0m df_city \u001b[38;5;241m=\u001b[39m \u001b[43mdf_city\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masfreq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Fill missing values using linear interpolation\u001b[39;00m\n\u001b[0;32m     39\u001b[0m df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex Value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_city[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex Value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39minterpolate(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\pandas\\core\\generic.py:9231\u001b[0m, in \u001b[0;36mNDFrame.asfreq\u001b[1;34m(self, freq, method, how, normalize, fill_value)\u001b[0m\n\u001b[0;32m   9124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   9125\u001b[0m \u001b[38;5;124;03mConvert time series to specified frequency.\u001b[39;00m\n\u001b[0;32m   9126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9227\u001b[0m \u001b[38;5;124;03m2000-01-01 00:03:00    3.0\u001b[39;00m\n\u001b[0;32m   9228\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   9229\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asfreq\n\u001b[1;32m-> 9231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masfreq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9232\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9238\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\pandas\\core\\resample.py:2837\u001b[0m, in \u001b[0;36masfreq\u001b[1;34m(obj, freq, method, how, normalize, fill_value)\u001b[0m\n\u001b[0;32m   2835\u001b[0m dti \u001b[38;5;241m=\u001b[39m date_range(obj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmin(), obj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmax(), freq\u001b[38;5;241m=\u001b[39mfreq, unit\u001b[38;5;241m=\u001b[39munit)\n\u001b[0;32m   2836\u001b[0m dti\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m-> 2837\u001b[0m new_obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m   2839\u001b[0m     new_obj\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m new_obj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnormalize()\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\pandas\\core\\frame.py:5378\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5359\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   5360\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,\n\u001b[0;32m   5361\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5376\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5377\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 5378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5382\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5389\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\pandas\\core\\generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5643\u001b[0m )\n",
      "File \u001b[1;32md:\\Anacondaa\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4429\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4428\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[1;32m-> 4429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4431\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "# Load dataset\n",
    "  # Update with your file path\n",
    "\n",
    "# Convert date column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df_city = df_city[~df_city.index.duplicated(keep='first')]\n",
    "\n",
    "# Count unique days per citydf_city.set_index('date', inplace=True)\n",
    "df_city = df_city.asfreq('D')\n",
    "\n",
    "# Fix: Remove duplicate date entries\n",
    "df_city = df_city[~df_city.index.duplicated(keep='first')]\n",
    "\n",
    "city_data_counts = df.groupby('City')['date'].nunique()\n",
    "\n",
    "\n",
    "# Categorize cities\n",
    "cities_with_2_years_data = city_data_counts[city_data_counts > 730].index.tolist()\n",
    "cities_with_less_than_2_years_data = city_data_counts[city_data_counts <= 730].index.tolist()\n",
    "\n",
    "# Store prediction results\n",
    "prediction_results = []\n",
    "\n",
    "for city in df['City'].unique():\n",
    "    df_city = df[df['City'] == city].copy()\n",
    "    df_city.set_index('date', inplace=True)\n",
    "    df_city = df_city.asfreq('D')\n",
    "    \n",
    "    # Fill missing values using linear interpolation\n",
    "    df_city['Index Value'] = df_city['Index Value'].interpolate(method='linear')\n",
    "    \n",
    "    # Use Iterative Imputer for consecutive missing values\n",
    "    imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "    df_city[['Index Value']] = imputer.fit_transform(df_city[['Index Value']])\n",
    "    \n",
    "    # Define features and target\n",
    "    df_city['day_of_year'] = df_city.index.dayofyear\n",
    "    df_city['year'] = df_city.index.year\n",
    "    X = df_city[['day_of_year', 'year']]\n",
    "    y = df_city['Index Value']\n",
    "    \n",
    "    # Split data for training/testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    if city in cities_with_2_years_data:\n",
    "        # Apply Holt-Winters\n",
    "        seasonal_periods = min(365, len(df_city) // 2)\n",
    "        model_hw = ExponentialSmoothing(y_train, trend='add', seasonal='add', seasonal_periods=seasonal_periods).fit()\n",
    "        hw_pred = model_hw.forecast(len(X_test))\n",
    "        X_train['hw_prediction'] = model_hw.fittedvalues\n",
    "        X_test['hw_prediction'] = hw_pred\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    model_xgb = XGBRegressor(objective='reg:squarederror', n_estimators=50, learning_rate=0.1, max_depth=3)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    xgb_pred = model_xgb.predict(X_test)\n",
    "    \n",
    "    # Final prediction\n",
    "    final_prediction = xgb_pred if city in cities_with_less_than_2_years_data else (0.5 * xgb_pred + 0.5 * hw_pred)\n",
    "    \n",
    "    # Compute confidence\n",
    "    mae = mean_absolute_error(y_test, final_prediction)\n",
    "    confidence = max(0, 100 - (mae / np.mean(y_test)) * 100)\n",
    "    \n",
    "    # Store results\n",
    "    prediction_results.append({\n",
    "        \"City\": city,\n",
    "        \"Predicted AQI\": round(final_prediction[-1], 2),\n",
    "        \"Prediction Confidence\": round(confidence, 2)\n",
    "    })\n",
    "\n",
    "# Output predictions\n",
    "for result in prediction_results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>City</th>\n",
       "      <th>No. Stations</th>\n",
       "      <th>Air Quality</th>\n",
       "      <th>Index Value</th>\n",
       "      <th>Prominent Pollutant</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>87</td>\n",
       "      <td>CO</td>\n",
       "      <td>Eastern Coastal Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>157</td>\n",
       "      <td>PM10</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>189</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Tropical wet &amp; dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>Agra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>179</td>\n",
       "      <td>PM10</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>156</td>\n",
       "      <td>PM10</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>94</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Tropical wet &amp; dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>Agra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>135</td>\n",
       "      <td>PM10</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>120</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Eastern Coastal Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>66</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Tropical wet &amp; dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poor</td>\n",
       "      <td>211</td>\n",
       "      <td>PM10</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>90</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Eastern Coastal Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>Agra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>84</td>\n",
       "      <td>O3</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-05-04</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poor</td>\n",
       "      <td>227</td>\n",
       "      <td>PM10</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-05-04</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>77</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Tropical wet &amp; dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-05-04</td>\n",
       "      <td>Agra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>104</td>\n",
       "      <td>O3</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-05-04</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>88</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Eastern Coastal Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-05-05</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>68</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Tropical wet &amp; dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-05-05</td>\n",
       "      <td>Agra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>88</td>\n",
       "      <td>O3</td>\n",
       "      <td>Indo-Gangetic Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-05-05</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>124</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Eastern Coastal Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>82</td>\n",
       "      <td>O3</td>\n",
       "      <td>Tropical wet &amp; dry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       City  No. Stations   Air Quality  Index Value  \\\n",
       "0  2015-05-01    Chennai           NaN  Satisfactory           87   \n",
       "1  2015-05-01   Varanasi           NaN      Moderate          157   \n",
       "2  2015-05-01  Hyderabad           NaN      Moderate          189   \n",
       "3  2015-05-01       Agra           NaN      Moderate          179   \n",
       "4  2015-05-02   Varanasi           NaN      Moderate          156   \n",
       "5  2015-05-02  Hyderabad           NaN  Satisfactory           94   \n",
       "6  2015-05-02       Agra           NaN      Moderate          135   \n",
       "7  2015-05-02    Chennai           NaN      Moderate          120   \n",
       "8  2015-05-03  Hyderabad           NaN  Satisfactory           66   \n",
       "9  2015-05-03   Varanasi           NaN          Poor          211   \n",
       "10 2015-05-03    Chennai           NaN  Satisfactory           90   \n",
       "11 2015-05-03       Agra           NaN  Satisfactory           84   \n",
       "12 2015-05-04   Varanasi           NaN          Poor          227   \n",
       "13 2015-05-04  Hyderabad           NaN  Satisfactory           77   \n",
       "14 2015-05-04       Agra           NaN      Moderate          104   \n",
       "15 2015-05-04    Chennai           NaN  Satisfactory           88   \n",
       "16 2015-05-05  Hyderabad           NaN  Satisfactory           68   \n",
       "17 2015-05-05       Agra           NaN  Satisfactory           88   \n",
       "18 2015-05-05    Chennai           NaN      Moderate          124   \n",
       "19 2015-05-06  Hyderabad           NaN  Satisfactory           82   \n",
       "\n",
       "   Prominent Pollutant                  Region  \n",
       "0                   CO  Eastern Coastal Region  \n",
       "1                 PM10    Indo-Gangetic Region  \n",
       "2                PM2.5      Tropical wet & dry  \n",
       "3                 PM10    Indo-Gangetic Region  \n",
       "4                 PM10    Indo-Gangetic Region  \n",
       "5                PM2.5      Tropical wet & dry  \n",
       "6                 PM10    Indo-Gangetic Region  \n",
       "7                PM2.5  Eastern Coastal Region  \n",
       "8                PM2.5      Tropical wet & dry  \n",
       "9                 PM10    Indo-Gangetic Region  \n",
       "10               PM2.5  Eastern Coastal Region  \n",
       "11                  O3    Indo-Gangetic Region  \n",
       "12                PM10    Indo-Gangetic Region  \n",
       "13               PM2.5      Tropical wet & dry  \n",
       "14                  O3    Indo-Gangetic Region  \n",
       "15               PM2.5  Eastern Coastal Region  \n",
       "16               PM2.5      Tropical wet & dry  \n",
       "17                  O3    Indo-Gangetic Region  \n",
       "18               PM2.5  Eastern Coastal Region  \n",
       "19                  O3      Tropical wet & dry  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
